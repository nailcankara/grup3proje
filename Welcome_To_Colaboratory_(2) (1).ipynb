{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome_To_Colaboratory (2).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlwKsbIuukZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/P16-AutoEncoders.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOSUfYSvunuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip P16-AutoEncoders.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DQDnFHvclYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/AutoEncoders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWVpegc6q1Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip ml-100k.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxAM99A_a9oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip ml-1m.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9r9Xvv7q3cZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_zcq2xDsiC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies = pd.read_csv('/content/AutoEncoders/ml-1m/movies.dat' , sep='::' , header = None, engine='python' , encoding='latin-1')\n",
        "users = pd.read_csv('/content/AutoEncoders/ml-1m/users.dat' , sep='::' , header = None, engine='python' , encoding='latin-1')\n",
        "ratings = pd.read_csv('/content/AutoEncoders/ml-1m/ratings.dat' , sep='::' , header = None, engine='python' , encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6glQaTlatdJ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = pd.read_csv('/content/AutoEncoders/ml-100k/u1.base' , delimiter= '\\t')\n",
        "training_set = np.array(training_set, dtype='int')\n",
        "test_set = pd.read_csv('/content/AutoEncoders/ml-100k/u1.test', delimiter= '\\t')\n",
        "test_set = np.array(test_set, dtype='int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g02Q3Yq2UQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_users = int(max(max(training_set[:,0]),max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]),max(test_set[:,1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEPsubvh5wCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(data):\n",
        "  new_data = []\n",
        "  for id_users in range(1 , nb_users+1):\n",
        "    id_movies = data[:,1][data[:,0] == id_users]\n",
        "    id_ratings = data[:,2][data[:,0] == id_users]\n",
        "    ratings = np.zeros(nb_movies)\n",
        "    ratings[id_movies-1] = id_ratings  \n",
        "    new_data.append(ratings)\n",
        "  return new_data\n",
        "\n",
        "training_set = np.array(convert(training_set))\n",
        "test_set = np.array(convert(test_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9MaYM7MAnlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense , Input\n",
        "from keras.optimizers import RMSprop\n",
        "import keras.backend as K\n",
        "K.clear_session()\n",
        "\n",
        "rms = RMSprop(learning_rate=0.01 , decay=0.5)\n",
        "\n",
        "input = Input(shape=(nb_movies,))\n",
        "encoded1 = Dense(160 , activation='sigmoid')(input)\n",
        "encoded2 = Dense(80 , activation='sigmoid')(encoded1)\n",
        "decoded1 = Dense(160 , activation='sigmoid')(encoded2)\n",
        "output = Dense(nb_movies)(decoded1)\n",
        "\n",
        "autoencoder = Model(input,output)\n",
        "autoencoder.compile(optimizer=rms, loss='mean_squared_error', metrics=['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzn1FbgUllLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdec74e2-9211-4f44-b516-5607b476fe4a"
      },
      "source": [
        "epochs = 100\n",
        "batch_size = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loss=0\n",
        "  s=0\n",
        "  for i in range(int(training_set.shape[0]/batch_size)):\n",
        "    batch_input = training_set[(i) * batch_size:(i + 1) * batch_size]\n",
        "    target = np.copy(batch_input)\n",
        "    if np.sum(training_set[i]) > 0:\n",
        "      predicted = autoencoder.predict_on_batch(training_set[(i) * batch_size:(i + 1) * batch_size])\n",
        "      K.stop_gradient(target)\n",
        "      predicted[target == 0] = 0\n",
        "      loss = autoencoder.train_on_batch(target,predicted)\n",
        "      mean_corrector = nb_movies/float(np.sum(target) + 1e-10)\n",
        "      train_loss +=  np.sqrt(loss[0]*mean_corrector)\n",
        "      s += 1\n",
        "\n",
        "  print('epoch: ' +str(epoch) + ' loss: '+str(train_loss/s))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 loss: 0.01740862315735166\n",
            "epoch: 1 loss: 0.0020120151799797687\n",
            "epoch: 2 loss: 0.00176524660739645\n",
            "epoch: 3 loss: 0.001648073398923099\n",
            "epoch: 4 loss: 0.0015767720735243185\n",
            "epoch: 5 loss: 0.0015275437254003241\n",
            "epoch: 6 loss: 0.001490704539544367\n",
            "epoch: 7 loss: 0.0014615202788846246\n",
            "epoch: 8 loss: 0.001437405646316554\n",
            "epoch: 9 loss: 0.0014168372251656255\n",
            "epoch: 10 loss: 0.001398868081145623\n",
            "epoch: 11 loss: 0.0013828827198464405\n",
            "epoch: 12 loss: 0.0013684634245880668\n",
            "epoch: 13 loss: 0.0013553164771937189\n",
            "epoch: 14 loss: 0.0013432304779787553\n",
            "epoch: 15 loss: 0.001332043868982863\n",
            "epoch: 16 loss: 0.001321636159978018\n",
            "epoch: 17 loss: 0.0013119081315178462\n",
            "epoch: 18 loss: 0.0013027823350046856\n",
            "epoch: 19 loss: 0.001294192427440752\n",
            "epoch: 20 loss: 0.0012860848614767739\n",
            "epoch: 21 loss: 0.0012784133282439847\n",
            "epoch: 22 loss: 0.0012711385504171238\n",
            "epoch: 23 loss: 0.0012642247883640134\n",
            "epoch: 24 loss: 0.0012576430982944365\n",
            "epoch: 25 loss: 0.0012513662327938593\n",
            "epoch: 26 loss: 0.0012453708895019365\n",
            "epoch: 27 loss: 0.0012396357332458202\n",
            "epoch: 28 loss: 0.0012341429571528185\n",
            "epoch: 29 loss: 0.0012288739670569234\n",
            "epoch: 30 loss: 0.0012238151476469316\n",
            "epoch: 31 loss: 0.0012189522413532843\n",
            "epoch: 32 loss: 0.0012142710902568073\n",
            "epoch: 33 loss: 0.0012097619089326051\n",
            "epoch: 34 loss: 0.0012054130941879459\n",
            "epoch: 35 loss: 0.0012012150071421298\n",
            "epoch: 36 loss: 0.001197159929226381\n",
            "epoch: 37 loss: 0.0011932386450835828\n",
            "epoch: 38 loss: 0.0011894453653592291\n",
            "epoch: 39 loss: 0.0011857711839686467\n",
            "epoch: 40 loss: 0.0011822104487878135\n",
            "epoch: 41 loss: 0.0011787577701577194\n",
            "epoch: 42 loss: 0.0011754067922074365\n",
            "epoch: 43 loss: 0.0011721527772475706\n",
            "epoch: 44 loss: 0.0011689911992187859\n",
            "epoch: 45 loss: 0.0011659175108837433\n",
            "epoch: 46 loss: 0.001162927132828187\n",
            "epoch: 47 loss: 0.0011600165702592184\n",
            "epoch: 48 loss: 0.0011571816160187232\n",
            "epoch: 49 loss: 0.0011544195963981616\n",
            "epoch: 50 loss: 0.0011517275623171184\n",
            "epoch: 51 loss: 0.0011491013529487512\n",
            "epoch: 52 loss: 0.001146538589411892\n",
            "epoch: 53 loss: 0.0011440373173376372\n",
            "epoch: 54 loss: 0.0011415949423320612\n",
            "epoch: 55 loss: 0.0011392083454362673\n",
            "epoch: 56 loss: 0.0011368764622319537\n",
            "epoch: 57 loss: 0.0011345958040339828\n",
            "epoch: 58 loss: 0.0011323660130742644\n",
            "epoch: 59 loss: 0.0011301835365449544\n",
            "epoch: 60 loss: 0.0011280473307910014\n",
            "epoch: 61 loss: 0.001125955431244454\n",
            "epoch: 62 loss: 0.0011239060640226438\n",
            "epoch: 63 loss: 0.0011218982934026445\n",
            "epoch: 64 loss: 0.0011199303900785418\n",
            "epoch: 65 loss: 0.0011180017828568466\n",
            "epoch: 66 loss: 0.0011161093792873332\n",
            "epoch: 67 loss: 0.0011142529374428079\n",
            "epoch: 68 loss: 0.0011124317349176047\n",
            "epoch: 69 loss: 0.0011106439937532736\n",
            "epoch: 70 loss: 0.001108888690972973\n",
            "epoch: 71 loss: 0.0011071656998716246\n",
            "epoch: 72 loss: 0.0011054725175704122\n",
            "epoch: 73 loss: 0.0011038090752706748\n",
            "epoch: 74 loss: 0.0011021744576473482\n",
            "epoch: 75 loss: 0.0011005678859270188\n",
            "epoch: 76 loss: 0.001098987899359246\n",
            "epoch: 77 loss: 0.0010974342971731622\n",
            "epoch: 78 loss: 0.0010959059259370765\n",
            "epoch: 79 loss: 0.0010944025879861866\n",
            "epoch: 80 loss: 0.0010929238916647518\n",
            "epoch: 81 loss: 0.00109146807156943\n",
            "epoch: 82 loss: 0.0010900348582467694\n",
            "epoch: 83 loss: 0.0010886233724322558\n",
            "epoch: 84 loss: 0.0010872336570183759\n",
            "epoch: 85 loss: 0.0010858652391481916\n",
            "epoch: 86 loss: 0.0010845171637485968\n",
            "epoch: 87 loss: 0.001083188209734902\n",
            "epoch: 88 loss: 0.0010818793485275085\n",
            "epoch: 89 loss: 0.0010805892831830804\n",
            "epoch: 90 loss: 0.0010793166118888337\n",
            "epoch: 91 loss: 0.0010780628701909899\n",
            "epoch: 92 loss: 0.0010768263010994018\n",
            "epoch: 93 loss: 0.0010756060180397542\n",
            "epoch: 94 loss: 0.0010744029957916684\n",
            "epoch: 95 loss: 0.0010732159050815965\n",
            "epoch: 96 loss: 0.0010720445163260343\n",
            "epoch: 97 loss: 0.0010708886603701816\n",
            "epoch: 98 loss: 0.001069748150580521\n",
            "epoch: 99 loss: 0.001068622048664996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSIG-19bn4cO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5847323c-5fe9-42f8-d0de-4111d0ba3ee6"
      },
      "source": [
        "i=0\n",
        "batch_size=1\n",
        "predicted_xd = autoencoder.predict_on_batch(training_set[(i) * batch_size:(i + 1) * batch_size])\n",
        "predicted_xd[0,0:20] , test_set[0,0:20]"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.01080162,  0.00159429, -0.00303094, -0.00087448,  0.00229199,\n",
              "         0.00223315,  0.00309813,  0.0024549 , -0.00139659, -0.00440375,\n",
              "        -0.00176306,  0.00563586,  0.00282036, -0.00320526, -0.002957  ,\n",
              "        -0.00225092, -0.0027782 , -0.00112683, -0.00085548, -0.00248449],\n",
              "       dtype=float32),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 3., 0., 5., 0., 5., 0., 0., 3.,\n",
              "        0., 0., 4.]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpRbYXoZaI4U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d14e2495-08c9-4847-db40-5dd4ce0bd239"
      },
      "source": [
        "test_loss=0\n",
        "s=0\n",
        "for i in range(int(training_set.shape[0]/batch_size)):\n",
        "  batch_input = training_set[(i) * batch_size:(i + 1) * batch_size]\n",
        "  target = test_set[(i) * batch_size:(i + 1) * batch_size]\n",
        "  if np.sum(test_set[i]) > 0:\n",
        "    predicted = autoencoder.predict_on_batch(training_set[(i) * batch_size:(i + 1) * batch_size])\n",
        "    K.stop_gradient(target)\n",
        "    predicted[target == 0] = 0\n",
        "    loss = autoencoder.train_on_batch(target,predicted)\n",
        "    mean_corrector = nb_movies/float(np.sum(target) + 1e-10)\n",
        "    test_loss +=  np.sqrt(loss[0]*mean_corrector)\n",
        "    s += 1\n",
        "\n",
        "print(' loss: '+str(test_loss/s))"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " loss: 0.0025676181844012224\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}